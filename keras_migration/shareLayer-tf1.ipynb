{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/i058959/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# CUDA DEVICE for keras\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# num_gpu = 0\n",
    "# gpu_devices = []\n",
    "\n",
    "# # gpu options, refer to https://stackoverflow.com/questions/39465503/cuda-error-out-of-memory-in-tensorflow\n",
    "# if os.environ.get('CUDA_VISIBLE_DEVICES') is not None and len(os.environ[\"CUDA_VISIBLE_DEVICES\"].strip()) > 0:\n",
    "#     num_gpu = len(os.environ[\"CUDA_VISIBLE_DEVICES\"].strip().split(\",\"))\n",
    "#     gpu_devices = [\"/gpu:%s\" % (i) for i in range(num_gpu)]\n",
    "#     gpu_options = tf.GPUOptions(allow_growth=True, allocator_type='BFC')\n",
    "#     sess = tf.Session(config = tf.ConfigProto(gpu_options=gpu_options, \\\n",
    "#                                               log_device_placement=True, allow_soft_placement=True))\n",
    "#     K.set_session(sess)\n",
    "\n",
    "# assert num_gpu > 0\n",
    "\n",
    "# refer to https://blog.csdn.net/weixin_55690929/article/details/116237139\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.utils import model_to_dot, plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Input(shape=(256, ))\n",
    "densor1 = Dense(64)\n",
    "X1 = Dense(128)(X)\n",
    "X2 = densor1(X1)\n",
    "X3 = Dense(32)(X2)\n",
    "\n",
    "model1 = Model(X, X3)\n",
    "model2 = Model(X, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = np.random.randn(5, 256)\n",
    "y3 = np.random.randn(5, 32)\n",
    "start_lr = 1e-3\n",
    "model1.compile(optimizer=Adam(start_lr, amsgrad=True), loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 43,232\n",
      "Trainable params: 43,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "=================================================================\n",
      "Total params: 41,152\n",
      "Trainable params: 41,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i058959/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "output1 = model2.predict(x_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights1 = model2.get_layer('dense_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(256, 128) dtype=float32>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(128,) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10674649, -0.09111714, -0.07347193, ..., -0.06821439,\n",
       "        -0.09577096, -0.12065038],\n",
       "       [-0.06943512, -0.01451701, -0.09098831, ..., -0.08800554,\n",
       "        -0.08463264,  0.10142192],\n",
       "       [-0.03669378, -0.12078676,  0.05507421, ..., -0.053891  ,\n",
       "        -0.04872113,  0.05631283],\n",
       "       ...,\n",
       "       [ 0.03838849, -0.06561705, -0.01489827, ...,  0.09190452,\n",
       "         0.00722638,  0.00814617],\n",
       "       [ 0.1059792 ,  0.09582174, -0.02034855, ..., -0.08433035,\n",
       "        -0.06512636, -0.03124806],\n",
       "       [-0.00384986,  0.11353031, -0.01205242, ...,  0.03728983,\n",
       "         0.11851263,  0.12271255]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(layer_weights1.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(layer_weights1.weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5 samples\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 39ms/sample - loss: 3.8411 - mean_squared_error: 3.8411\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 712us/sample - loss: 2.5022 - mean_squared_error: 2.5022\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 583us/sample - loss: 1.5765 - mean_squared_error: 1.5765\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 546us/sample - loss: 0.9873 - mean_squared_error: 0.9873\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 481us/sample - loss: 0.6496 - mean_squared_error: 0.6496\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 544us/sample - loss: 0.4796 - mean_squared_error: 0.4796\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 582us/sample - loss: 0.4052 - mean_squared_error: 0.4052\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 560us/sample - loss: 0.3739 - mean_squared_error: 0.3739\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 540us/sample - loss: 0.3540 - mean_squared_error: 0.3540\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 591us/sample - loss: 0.3311 - mean_squared_error: 0.3311\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 604us/sample - loss: 0.3023 - mean_squared_error: 0.3023\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 587us/sample - loss: 0.2699 - mean_squared_error: 0.2699\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 650us/sample - loss: 0.2374 - mean_squared_error: 0.2374\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 602us/sample - loss: 0.2077 - mean_squared_error: 0.2077\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 544us/sample - loss: 0.1820 - mean_squared_error: 0.1820\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 550us/sample - loss: 0.1606 - mean_squared_error: 0.1606\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 531us/sample - loss: 0.1428 - mean_squared_error: 0.1428\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 632us/sample - loss: 0.1278 - mean_squared_error: 0.1278\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 603us/sample - loss: 0.1148 - mean_squared_error: 0.1148\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 588us/sample - loss: 0.1031 - mean_squared_error: 0.1031\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 585us/sample - loss: 0.0924 - mean_squared_error: 0.0924\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 512us/sample - loss: 0.0824 - mean_squared_error: 0.0824\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 569us/sample - loss: 0.0731 - mean_squared_error: 0.0731\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 568us/sample - loss: 0.0645 - mean_squared_error: 0.0645\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 616us/sample - loss: 0.0567 - mean_squared_error: 0.0567\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 586us/sample - loss: 0.0500 - mean_squared_error: 0.0500\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 579us/sample - loss: 0.0444 - mean_squared_error: 0.0444\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 548us/sample - loss: 0.0399 - mean_squared_error: 0.0399\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 584us/sample - loss: 0.0365 - mean_squared_error: 0.0365\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 560us/sample - loss: 0.0337 - mean_squared_error: 0.0337\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 682us/sample - loss: 0.0313 - mean_squared_error: 0.0313\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 597us/sample - loss: 0.0289 - mean_squared_error: 0.0289\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 608us/sample - loss: 0.0265 - mean_squared_error: 0.0265\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 535us/sample - loss: 0.0239 - mean_squared_error: 0.0239\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 582us/sample - loss: 0.0213 - mean_squared_error: 0.0213\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 605us/sample - loss: 0.0187 - mean_squared_error: 0.0187\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 673us/sample - loss: 0.0165 - mean_squared_error: 0.0165\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 542us/sample - loss: 0.0147 - mean_squared_error: 0.0147\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 632us/sample - loss: 0.0133 - mean_squared_error: 0.0133\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 680us/sample - loss: 0.0123 - mean_squared_error: 0.0123\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 572us/sample - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 583us/sample - loss: 0.0110 - mean_squared_error: 0.0110\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 671us/sample - loss: 0.0104 - mean_squared_error: 0.0104\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 598us/sample - loss: 0.0098 - mean_squared_error: 0.0098\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 658us/sample - loss: 0.0090 - mean_squared_error: 0.0090\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 681us/sample - loss: 0.0082 - mean_squared_error: 0.0082\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 648us/sample - loss: 0.0073 - mean_squared_error: 0.0073\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 518us/sample - loss: 0.0063 - mean_squared_error: 0.0063\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 518us/sample - loss: 0.0053 - mean_squared_error: 0.0053\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 522us/sample - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 592us/sample - loss: 0.0036 - mean_squared_error: 0.0036\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 647us/sample - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 610us/sample - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 643us/sample - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 633us/sample - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 557us/sample - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 626us/sample - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 604us/sample - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 709us/sample - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 720us/sample - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 601us/sample - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 562us/sample - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 632us/sample - loss: 0.0013 - mean_squared_error: 0.0013\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 618us/sample - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 612us/sample - loss: 9.3493e-04 - mean_squared_error: 9.3493e-04\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 694us/sample - loss: 7.9220e-04 - mean_squared_error: 7.9220e-04\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 620us/sample - loss: 6.9672e-04 - mean_squared_error: 6.9672e-04\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 631us/sample - loss: 6.4109e-04 - mean_squared_error: 6.4109e-04\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 596us/sample - loss: 6.1004e-04 - mean_squared_error: 6.1004e-04\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 613us/sample - loss: 5.8689e-04 - mean_squared_error: 5.8689e-04\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 625us/sample - loss: 5.5960e-04 - mean_squared_error: 5.5960e-04\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 649us/sample - loss: 5.2386e-04 - mean_squared_error: 5.2386e-04\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 649us/sample - loss: 4.8186e-04 - mean_squared_error: 4.8186e-04\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 584us/sample - loss: 4.3848e-04 - mean_squared_error: 4.3848e-04\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 658us/sample - loss: 3.9741e-04 - mean_squared_error: 3.9741e-04\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 586us/sample - loss: 3.5935e-04 - mean_squared_error: 3.5935e-04\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 596us/sample - loss: 3.2255e-04 - mean_squared_error: 3.2255e-04\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 634us/sample - loss: 2.8485e-04 - mean_squared_error: 2.8485e-04\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 678us/sample - loss: 2.4577e-04 - mean_squared_error: 2.4577e-04\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 628us/sample - loss: 2.0745e-04 - mean_squared_error: 2.0745e-04\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 639us/sample - loss: 1.7370e-04 - mean_squared_error: 1.7370e-04\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 625us/sample - loss: 1.4790e-04 - mean_squared_error: 1.4790e-04\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 658us/sample - loss: 1.3105e-04 - mean_squared_error: 1.3105e-04\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 679us/sample - loss: 1.2137e-04 - mean_squared_error: 1.2137e-04\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 612us/sample - loss: 1.1553e-04 - mean_squared_error: 1.1553e-04\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 598us/sample - loss: 1.1051e-04 - mean_squared_error: 1.1051e-04\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 615us/sample - loss: 1.0479e-04 - mean_squared_error: 1.0479e-04\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 653us/sample - loss: 9.8332e-05 - mean_squared_error: 9.8332e-05\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 622us/sample - loss: 9.1683e-05 - mean_squared_error: 9.1683e-05\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 609us/sample - loss: 8.5141e-05 - mean_squared_error: 8.5141e-05\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 595us/sample - loss: 7.8459e-05 - mean_squared_error: 7.8459e-05\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 600us/sample - loss: 7.1195e-05 - mean_squared_error: 7.1195e-05\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 631us/sample - loss: 6.3264e-05 - mean_squared_error: 6.3264e-05\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 636us/sample - loss: 5.5178e-05 - mean_squared_error: 5.5178e-05\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 639us/sample - loss: 4.7754e-05 - mean_squared_error: 4.7754e-05\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 597us/sample - loss: 4.1565e-05 - mean_squared_error: 4.1565e-05\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 587us/sample - loss: 3.6611e-05 - mean_squared_error: 3.6611e-05\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 673us/sample - loss: 3.2462e-05 - mean_squared_error: 3.2462e-05\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 751us/sample - loss: 2.8691e-05 - mean_squared_error: 2.8691e-05\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 580us/sample - loss: 2.5187e-05 - mean_squared_error: 2.5187e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fedfc2378e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_samples, y3, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = model2.predict(x_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights2 = model2.get_layer('dense_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10235845, -0.08533824, -0.06451959, ..., -0.06266831,\n",
       "        -0.10204776, -0.11085568],\n",
       "       [-0.07516585, -0.01103969, -0.0800341 , ..., -0.08271637,\n",
       "        -0.07506958,  0.09751236],\n",
       "       [-0.02165939, -0.11528898,  0.06109155, ..., -0.05399107,\n",
       "        -0.03317871,  0.07049937],\n",
       "       ...,\n",
       "       [ 0.0253266 , -0.07253925, -0.02048196, ...,  0.09239022,\n",
       "        -0.00673127, -0.01205675],\n",
       "       [ 0.09903862,  0.09183697, -0.02749237, ..., -0.0871641 ,\n",
       "        -0.0809947 , -0.04626979],\n",
       "       [-0.0215675 ,  0.10534785, -0.018583  , ...,  0.03546347,\n",
       "         0.12386263,  0.11235522]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(layer_weights2.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.6375309e-04,  3.9185295e-03,  7.5380756e-03,  5.7024352e-04,\n",
       "       -7.3432955e-03,  1.2265694e-02,  7.5661712e-03, -1.1918503e-02,\n",
       "       -8.3040223e-03,  1.1312979e-02,  5.0026407e-03,  9.5749497e-03,\n",
       "       -3.3175216e-05, -6.9280765e-03,  3.9229067e-03,  7.4922638e-03,\n",
       "       -6.6529368e-03,  9.6891224e-03, -1.2891995e-02, -3.3181920e-03,\n",
       "        2.4793306e-03,  4.9423887e-03, -7.8427391e-03, -7.5899544e-03,\n",
       "       -1.1345633e-02, -4.1289488e-03,  2.7549884e-03, -4.8926682e-03,\n",
       "       -7.3350134e-04,  6.0013197e-03,  7.3562874e-03,  3.8846490e-05,\n",
       "       -7.3292749e-03,  4.6952898e-03, -2.8505267e-03, -4.1206591e-03,\n",
       "        9.0117631e-03,  3.3146697e-03, -1.2784131e-02, -9.2696091e-03,\n",
       "        1.0590844e-02,  4.9243127e-03,  8.5671702e-03,  5.4866862e-03,\n",
       "       -3.8967575e-03,  5.2371887e-03,  5.3191721e-03,  4.2213462e-03,\n",
       "       -6.5635857e-03,  5.4042321e-03,  4.8644762e-03, -5.7386030e-03,\n",
       "       -5.4510217e-03,  4.3528522e-03, -4.3114573e-03, -1.3908277e-03,\n",
       "       -9.4933370e-03,  2.8765188e-03,  3.6807666e-03, -1.9934529e-02,\n",
       "       -6.5595149e-03,  3.7895257e-03,  8.5899755e-03,  6.8677259e-03,\n",
       "       -1.9677235e-03, -7.2888294e-03, -3.9319661e-03,  1.1113844e-02,\n",
       "        4.9134069e-03, -5.0865351e-03, -1.0298599e-02, -1.3562851e-02,\n",
       "       -4.7247149e-03,  5.1937602e-03, -1.7908649e-03, -5.4680072e-03,\n",
       "       -1.4452097e-02, -4.0621520e-03,  7.5898487e-03,  2.0149439e-03,\n",
       "        8.8512199e-03, -7.8289593e-03,  6.5567475e-03,  5.6175040e-03,\n",
       "       -7.2383597e-03, -7.3987767e-03, -5.6709866e-03,  2.8096880e-03,\n",
       "        5.0956532e-03,  4.7378549e-03,  9.1516636e-03,  7.7235256e-03,\n",
       "       -9.0973144e-03,  2.4294441e-03,  5.2327788e-03,  9.9310298e-03,\n",
       "       -2.1153134e-03, -9.1215195e-03, -6.3203569e-03, -9.4341449e-03,\n",
       "        9.4698342e-03,  7.9560652e-03,  6.3177911e-03, -4.2861635e-03,\n",
       "        2.9005927e-03,  1.8592279e-02, -4.1046587e-04, -9.3796011e-03,\n",
       "        6.3535231e-03,  1.6621902e-03, -8.6773690e-03, -7.2428952e-03,\n",
       "        3.1794298e-03,  6.3221008e-03,  6.1629894e-03, -1.1430496e-02,\n",
       "       -5.0197062e-03,  2.5841931e-03, -6.8143941e-03,  6.7862798e-03,\n",
       "        1.1721528e-02, -4.2991843e-03,  1.1428273e-02, -1.0868059e-02,\n",
       "       -5.3739459e-03,  2.7164833e-03,  1.0600060e-02,  5.4277703e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(layer_weights2.weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.all(output1 == output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
