{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Demo for tf.string_split\n",
    "\n",
    "Reference:\n",
    "*  [Tensorflow tf.string_split Demo](https://github.com/tensorflow/transform/blob/master/tensorflow_transform/mappers_test.py#L117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_tensor = tf.constant(['One was Johnny', 'Two was a rat'])\n",
    "tokenized_tensor = tf.string_split(string_tensor, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[0, 0],\n",
      "       [0, 1],\n",
      "       [0, 2],\n",
      "       [1, 0],\n",
      "       [1, 1],\n",
      "       [1, 2],\n",
      "       [1, 3]]), values=array([b'One', b'was', b'Johnny', b'Two', b'was', b'a', b'rat'],\n",
      "      dtype=object), dense_shape=array([2, 4]))\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tokenized_tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to convert [tf.string] to [np.array]\n",
    "\n",
    "1. as **tf.map_fn** has to keep dimension, just use tf.map_fn for string process and keep_dim\n",
    "2. **keypoints:**:\n",
    "   * using tf.string_split for split for all, then to SparseTensorValue\n",
    "   * convert SparseTensorValue to dense matrix, via tf.sparse_tensor_to_dense\n",
    "   * convert all of element of dense from string to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "## 1. example 1 : just for converting to qualified string matrix\n",
    "x = tf.placeholder(tf.string)\n",
    "def parse(x):\n",
    "    x = tf.regex_replace(x, \"\\[\", \"\")\n",
    "    x = tf.regex_replace(x, \"\\]\", \"\")\n",
    "    return x\n",
    "\n",
    "output_strs = tf.map_fn(parse, x)\n",
    "t1 = tf.string_split(output_strs, delimiter=\",\")\n",
    "target_indices, target_values = t1.indices, tf.strings.to_number(t1.values)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(target_values, feed_dict={x: [\"[1.0,2.0]\", \"[2.0,3.0]\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "## 2. example 2 : matrix conversion for follow-ups\n",
    "x = tf.placeholder(tf.string)\n",
    "y = tf.map_fn(lambda elem: tf.regex_replace(elem, \"[\\[|\\]]\", \"\"), x, dtype=tf.string)\n",
    "y = tf.string_split(y, delimiter=\",\")\n",
    "y = tf.sparse_tensor_to_dense(y, default_value=\"\")\n",
    "y = tf.strings.to_number(y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y, feed_dict={x: [\"[1.0,2.0]\", \"[2.0,3.0]\"]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
