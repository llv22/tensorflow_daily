{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL homework 5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loss Function\n",
    "\n",
    "### 1.1 Policy Loss\n",
    "\n",
    "Case 1: **Reinforcement Learning Loss** \n",
    "$$ \\nabla_{\\phi} J_{\\pi}(\\phi) = \\mathop{{}\\mathbb{E}}_{s \\sim D} \\lbrace \\mathop{{}\\mathbb{E}}_{a \\sim \\pi_{\\phi}(a|S)} [\\nabla_{\\phi} \\log \\pi(a|s) (\\alpha \\cdot log \\pi_{\\phi} (a|s) - Q_{\\theta}(s, a)) + b(s) | s]  \\rbrace $$ \n",
    "\n",
    "Case 2: **Reparameter Trick**\n",
    "$$ \\nabla_{\\phi} J_{\\pi}(\\phi) = \\mathop{{}\\mathbb{E}}_{s \\sim D} \\lbrace \\mathop{{}\\mathbb{E}}_{\\epsilon \\sim N(0, I)} [\\alpha \\cdot \\log \\pi_{\\phi}(f_{\\phi}(\\epsilon;s)|s) - Q_{\\theta}(s, f_{\\phi}(\\epsilon; s)) | s] \\rbrace $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.gen_array_ops.stop_gradient(input, name=None)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stop_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.ops.distributions.normal.Normal"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfd.Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Squashing\n",
    "\n",
    "### 2.1 Math Reasoning  \n",
    "Reference: https://tex.stackexchange.com/questions/74125/how-do-i-put-text-over-symbols\n",
    "\n",
    "* **Invertible functions' chain rule**\n",
    "\n",
    "$$Z^{(N)} = (f_N \\circ \\cdots \\circ f_1)(z^0) \\iff \\log p(z^{(N)}) = log(p(z^{(0)})) - \\sum_{i=1}^{N} \\left| \\det(\\frac{\\partial f_i(z^{(i-1)})}{\\partial z^{(i-1)}}) \\right|$$\n",
    "\n",
    "where $\\frac{\\partial f_i(z^{(i-1)})}{\\partial z^{(i-1)}}$ is Jacobian of $f_i$, and $\\det$ is the determinant.\n",
    "\n",
    "* **Squashing via tanh for action A**\n",
    "\n",
    "<!--\n",
    "$$ a = \\tanh \\left(b_{\\phi}(s) + A_{\\phi}(s)\\epsilon \\right) \\iff z=f_1(\\epsilon) \\triangleq b(s) + A(s) \\epsilon, a = f_2(z) \\triangleq \\tanh(z) $$\n",
    "\n",
    "or \n",
    "\n",
    "$$ a = \\tanh \\left(b_{\\phi}(s) + A_{\\phi}(s)\\epsilon \\right) \\iff z=f_1(\\epsilon) \\equiv b(s) + A(s) \\epsilon, a = f_2(z) \\equiv \\tanh(z) $$\n",
    "\n",
    "or \n",
    "-->\n",
    "\n",
    "$$a = \\tanh \\left(b_{\\phi}(s) + A_{\\phi}(s)\\epsilon \\right) \\iff z=f_1(\\epsilon) \\stackrel{\\text{def}}{=} b(s) + A(s) \\epsilon, a = f_2(z) \\stackrel{\\text{def}}{=}\\tanh(z) $$\n",
    "\n",
    "As making f=$\\tanh$, we have the Jacobian is a diagonal matrix with $\\frac{\\partial \\tanh(z_i)}{\\partial z_i} = 1 - \\tanh ^2(z_i)$, finally we get\n",
    "\n",
    "$$\\log \\left|  det(\\frac{\\partial f_2(z)}{\\partial z}) \\right| = \\sum_{i=1}^{|A|} \\log \\left(1 - \\tanh^2(z_i)\\right)$$\n",
    "\n",
    "Bonus Task:\n",
    "\n",
    "$$\\log \\left(1 - \\tanh^2(z_i)\\right) = 2 \\log 2 + 2 z_i - softplus(2z_i), \\text{where } softplus(x) = \\log(1+e^x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SAC with Two Q-Functions\n",
    "\n",
    "* Key points: using Q1 and Q2 with different parameter $\\theta_1$ and $\\theta_2$, then use $Q(s,a)=\\min(Q_1(s,a), Q_2(s,a))$ to restrict the sampling upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
