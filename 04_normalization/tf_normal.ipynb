{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using tf to normalize\n",
    "size = 100\n",
    "adv_n = np.random.rand(100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, std = [0.5233243460357401, 0.29831162737197475]\n"
     ]
    }
   ],
   "source": [
    "def stddev(v, mean):\n",
    "#     adv_std = tf.sqrt(tf.reduce_mean(tf.square(v - mean)))\n",
    "    adv_std = tf.sqrt(tf.reduce_mean(tf.squared_difference(v, mean)))\n",
    "    return adv_std\n",
    "\n",
    "adv_mean = tf.reduce_mean(adv_n)\n",
    "adv_std = stddev(adv_n, adv_mean)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"mean, std = %s\" % (sess.run([adv_mean, adv_std])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized mean, std = [-1.8207657603852566e-16, 0.9999999999999998]\n"
     ]
    }
   ],
   "source": [
    "# after normalization to check gaussion\n",
    "adv_normal_n = (adv_n - adv_mean) / adv_std \n",
    "adv_normal_mean = tf.reduce_mean(adv_normal_n)\n",
    "adv_normal_std = stddev(adv_normal_n, adv_normal_mean)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"normalized mean, std = %s\" % (sess.run([adv_normal_mean, adv_normal_std])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean, std = [0.5233244, 0.29831162]\n"
     ]
    }
   ],
   "source": [
    "adv_mean, adv_variance = tf.nn.moments(tf.constant(adv_n, dtype=tf.float32), axes=[0])\n",
    "adv_std = tf.sqrt(adv_variance)\n",
    "with tf.Session() as sess:\n",
    "    print(\"mean, std = %s\" % (sess.run([adv_mean, adv_std])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized mean, std = [-7.390976e-08, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# after normalization to check gaussion\n",
    "adv_normal_n = (adv_n - adv_mean) / adv_std \n",
    "adv_normal_mean = tf.reduce_mean(adv_normal_n)\n",
    "adv_normal_std = stddev(adv_normal_n, adv_normal_mean)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"normalized mean, std = %s\" % (sess.run([adv_normal_mean, adv_normal_std])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle adv_std $\\approx$ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate adv_std is very small\n",
    "# adv_std = tf.constant(1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized mean, std = [-7.390976e-08, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# after normalization to check gaussion\n",
    "adv_normal_n = tf.cond(adv_std < 1e-7, lambda: (adv_n - adv_mean), lambda: (adv_n - adv_mean) / adv_std)\n",
    "adv_normal_mean = tf.reduce_mean(adv_normal_n)\n",
    "adv_normal_std = stddev(adv_normal_n, adv_normal_mean)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"normalized mean, std = %s\" % (sess.run([adv_normal_mean, adv_normal_std])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient\n",
    "\n",
    "Recall that the expression for the policy gradient PG is  \n",
    "    $$ PG = E_{\\tau} [\\sum_{t=0}^T \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t|s_t) * (Q_t - b_t )] $$  \n",
    "where  \n",
    "    $ tau=(s_0, a_0, ...) $ is a trajectory,  \n",
    "    $ Q_t $ is the Q-value at time t, $Q^{\\pi}(s_t, a_t)$,  \n",
    "    and $ b_t $ is a baseline which may depend on $s_t$.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global setting of Q_n\n",
    "N = 5\n",
    "tau_len = 100\n",
    "# list of 1D np.array - rewards\n",
    "re_n = list(np.random.rand(N, tau_len))\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.970299, 0.9801  , 0.99    , 1.      ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma ** np.array([3, 2, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: trajectory-based PG \n",
    "            \n",
    "(reward_to_go = False)\n",
    "\n",
    "Instead of $Q^{\\pi}(s_t, a_t)$, we use the total discounted reward summed over \n",
    "entire trajectory (regardless of which time step the Q-value should be for). \n",
    "\n",
    "For this case, the policy gradient estimator is\n",
    "\n",
    "  $$ E_{\\tau} [\\sum_{t=0}^T \\nabla_{\\theta} \\log \\pi_{\\theta}(a_t|s_t) * Ret(\\tau)] $$\n",
    "\n",
    "where\n",
    "\n",
    "  $ Ret(\\tau) = \\sum_{t'=0}^T \\gamma^{t'} r_{t'} $.\n",
    "\n",
    "**Thus, you should compute**\n",
    "\n",
    "  $ Q_t = Ret(\\tau) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all reward step t=1:T, they have the same total rewards, just copy * len(re_tau)\n",
    "Q_n = np.concatenate([[sum(re_tau * (gamma ** np.arange(len(re_tau))[::-1]))] * len(re_tau) for re_tau in re_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_discount_rewards(rewards, gamma):\n",
    "    return sum((gamma**i) * rewards[i] for i in range(len(rewards)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_n1 = np.concatenate([[sum_discount_rewards(re_tau[::-1], gamma)] * len(re_tau)\n",
    "                    for re_tau in re_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.abs(Q_n - q_n1) < 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gamma ** np.array(range(len(re_n[0]))[::-1])) == len(re_n[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: reward-to-go PG \n",
    "\n",
    "(reward_to_go = True)\n",
    "\n",
    "Here, you estimate $Q^{\\pi}(s_t, a_t)$ by the discounted sum of rewards starting\n",
    "from time step t. \n",
    "\n",
    "**Thus, you should compute**\n",
    "\n",
    "  $$ Q_t = \\sum_{t'=t}^T \\gamma^{(t'-t)} * r_{t'} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten result to 500\n",
    "Q_n = np.concatenate([[sum(re_tau[::-1][:len(re_tau)-start] * (gamma ** np.arange(len(re_tau)-start))) \\\n",
    "        for start in range(len(re_tau))] \\\n",
    "       for re_tau in re_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Q_n[99] == re_n[0][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify to be consistent with https://github.com/Kelym/DeepRL-UCB2017-Homework/blob/master/hw2/train_pg.py\n",
    "def discount_rewards_to_go(rewards, gamma):\n",
    "    res = [] \n",
    "    future_reward = 0\n",
    "    for r in reversed(rewards):\n",
    "        future_reward = future_reward * gamma + r\n",
    "        res.append(future_reward)\n",
    "    return res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_n1 = np.concatenate([discount_rewards_to_go(re_tau, gamma) for re_tau in re_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify to be consistent with https://github.com/Kelym/DeepRL-UCB2017-Homework/blob/master/hw2/train_pg.py\n",
    "def discount_rewards_to_acc_go(rewards, gamma):\n",
    "    res = []\n",
    "    for i in range(len(rewards)):\n",
    "        res.append(sum(rewards[::-1][:i+1] * (gamma ** np.arange(i+1))))\n",
    "    return res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_n2 = np.concatenate([discount_rewards_to_acc_go(re_tau, gamma) for re_tau in re_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056796565636278"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_n1[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900976793758099"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_n2[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.900976793758099"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_n[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.abs(q_n2 - Q_n) < 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.394413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.451254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.071472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.210055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.569741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.098954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  500.000000\n",
       "mean     0.394413\n",
       "std      0.451254\n",
       "min      0.000000\n",
       "25%      0.071472\n",
       "50%      0.210055\n",
       "75%      0.569741\n",
       "max      2.098954"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(np.abs(Q_n - q_n1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
